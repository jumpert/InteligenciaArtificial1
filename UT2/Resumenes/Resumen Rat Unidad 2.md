<h1 style="color: blue"> Resumen Rat Unidad 2 </h1>

üìò Master Machine Learning Algorithms

> ***Cap√≠tulo 3 ‚ÄúAlgorithms Learn a Mapping from Input to Output‚Äù***


Es importante tener presente el error (e) cuando consideramos calcular 

$$Y = f(X) + e$$

Donde $f$ es la funci√≥n que queremos aprender y $e$ es el error que se comete al estimar $f$.

### Learning a Function to Make Predictions

Asignarle valores a $X$ para que la funci√≥n $f$ nos devuelva un valor $Y$, que permita realizar predicciones lo m√°s cercanas a la realidad.

### Techniques For Learn a Function

Existen diferentes formas de hacerlo, cada cual tiene diferentes asunciones y limitaciones, pueden ser lineales o no lineales.

Debemos evaluar entre las diferentes t√©cnicas, cu√°l es la que mejor se ajusta a nuestro problema.

> ***Cap√≠tulo 4 ‚ÄúParametric and Nonparametric Machine Learning Algorithms‚Äù***

- Los algoritmos param√©tricos simplifican la funci√≥n a una forma funcional conocida.
- Los algoritmos no param√©tricos pueden aprender cualquier mapeo desde las entradas hasta las salidas.
- Todos los algoritmos se pueden organizar entre grupos param√©tricos y no param√©tricos.

### Parametric Machine Learning Algorithms

Las asunciones pueden simplificar en gran medida el proceso de aprendizaje, pero puede incluso limitar lo que se puede aprender.

Los algoritmos que simplifican la funci√≥n a una forma conocida se denominan algoritmos de aprendizaje autom√°tico param√©trico.

Los algoritmos involucran dos pasos:
1. Seleccionar un formulario para la funci√≥n
2. Aprender los coeficientes de la funci√≥n desde los datos de entrenamiento.

Una funcionalidad conocida es una funci√≥n lineal, por ejemplo:

$$B0 + B1 * X1 + B2 * X2 = 0$$

Donde $B0$, $B1$ y $B2$ son los coeficientes que deben ser aprendidos a partir de los datos de entrenamiento. Y $X1$ y $X2$ son las variables de entrada. Suponiendo que el formulario funcional simplifica el proceso de aprendizaje. Ahora, todos necesitamos que estimen el coheficionte d de la ecuaci√≥n y tenemos un modelo predictivo al problema.

**Algunos ejemplos de algoritmos param√©tricos son:**
- Regresi√≥n log√≠stica
- An√°lisis discriminante lineal
- Perceptr√≥n

*Beneficios de  Algoritmos para Aprendizaje automatizado*

+ Simplicidad
+ Rapidez
+ Menos informaci√≥n

*Limitaciones de Algoritmos para Aprendizaje automatizado*

+ Restricciones:Al elegir una forma funcional, estos m√©todos quedan altamente limitados a la forma especificada.

- Complejidad Limitada: Estos m√©todos son m√°s adecuados para problemas m√°s simples.
  
- Ajuste Deficiente: En la pr√°ctica, es poco probable que estos m√©todos se ajusten correctamente a la funci√≥n de mapeo subyacente.
  
### Nonparametric Machine Learning Algorithms

Los algoritmos que no hacen suposiciones sobre la forma funcional son llamados algoritmos de aprendizaje autom√°tico no param√©tricos.

Los m√©todos no param√©tricos son √∫tiles cuando se dispone de una gran cantidad de datos y no se cuenta con conocimiento previo, y cuando no se desea preocuparse demasiado por elegir exactamente las caracter√≠sticas adecuadas.

**Algunos ejemplos de algoritmos no param√©tricos son:**

- Decision Trees como CART y C4.5
- Naive Bayes
- Support Vector Machines
- Neural Networks

*Beneficios de Algoritmos para Aprendizaje automatizado*

+ Flexibilidad: Pueden aprender cualquier cosa.
+ Potencia: No hay l√≠mite en lo que pueden aprender.
+ Performance: Pueden ajustarse a los datos de entrenamiento.

*Limitaciones de Algoritmos para Aprendizaje automatizado*

+ M√°s datos: Requieren una gran cantidad de datos de entrenamiento para estimar la funci√≥n de mapeo de entrada a salida.
+ M√°s lentos:  Mucho m√°s lento para entrenar, ya que a menudo tienen muchos m√°s par√°metros para entrenar.
+ Sobreajuste: m√°s riesgo de sobreajuste de los datos de entrenamiento y es m√°s dif√≠cil explicar por qu√© se hacen predicciones espec√≠ficas.


> ***Cap√≠tulo 5 ‚ÄúSupervised and Unsupervised Machine Learning Algorithms‚Äù***

### Supervised Machine Learning 

La Mayor√≠a utiliza este tipo de ML, tomando las variables $X$ y aprendiendo la funcion de mapeo de la entrada a la salida $Y$.

$$Y = f(X)$$

**Clasificaci√≥n:** Un problema de clasificaci√≥n es cuando la variable de salida es una categor√≠a, como rojo o azul o enfermedad y no enfermedad.
**Regresi√≥n:** Un problema de regresi√≥n es cuando la variable de salida es un valor real, como d√≥lares o peso.

Algunos ejemplos de algoritmos de aprendizaje supervisado son:

- Regresi√≥n lineal para problemas de regresi√≥n.
- Bosques aleatorios para problemas de clasificaci√≥n y regresi√≥n.
- Vectores de soporte para problemas de clasificaci√≥n.

### Unsupervised Machine Learning

Los algoritmos de aprendizaje autom√°tico no supervisados aprenden de los datos de entrada $X$, sin una variable de salida conocida.

$$X = f()$$

Los problemas de aprendizaje no supervisados se pueden agrupar en problemas de agrupaci√≥n y asociaci√≥n.

- **Clustering**: Identificar grupos inherentes en los datos, como categorizar clientes seg√∫n sus patrones de compra.
- **Asociaci√≥n**: Descubrir reglas que describen relaciones significativas en los datos, como la tendencia de las personas que compran $A$ a tambi√©n comprar $B$.

Algunos ejemplos de estos algoritmos son:

- K-Means para problemas de agrupaci√≥n.
- Apriori para problemas de asociaci√≥n.

### Semi-supervised Machine Learning

Los algoritmos de aprendizaje autom√°tico semisupervisados aprenden de los datos de entrada $X$ y de una variable de salida conocida $Y$.

### Resumen 


**Supervisado:** Todos los datos est√°n etiquetados y los algoritmos aprenden a predecir la salida a partir de los datos de entrada.
**No supervisado:** Todos los datos est√°n sin etiquetar y los algoritmos aprenden la estructura inherente de los datos de entrada.
**Semi-supervisado:** Algunos datos est√°n etiquetados, pero la mayor√≠a no lo est√°, y se pueden utilizar t√©cnicas tanto supervisadas como no supervisadas en combinaci√≥n.


> ***Cap√≠tulo 6 ‚ÄúThe Bias-Variance Trade-Off‚Äù***

Despu√©s de leer este cap√≠tulo, sabr√°:	
- Los errores pueden ser descompuestos en error de sesgo y error de varianza.
- Los sesgos refieren a simplificar asunciones hechas por algoritmos para hacer el problema m√°s f√°cil de resolver.
- La varianza se refiere a la sensibilidad  de un modelo para cambiar los datos de entrenamiento.
- Las aplicaciones de ML por modelos predictivos son mejor entendidas a trav√©s del marco de sesgo-varianza.
  
  ### Descripcion de sesgo y varianza

El error de predicci√≥n de un modelo se puede descomponer en 3 partes:

1. Error de sesgo
2. Error de varianza
3. Error irreducible

El _error irreducible_ se puede deber a factores como el desconocimiento de la influencia del mapeo de las variables de entrada con las de salida. Por tanto nos centraremos en el error de sesgo y varianza.

### Error de sesgo

Los sesgos son simplificaciones de asunciones hechas por un modelo para hacer la funcion objetivo m√°s f√°cil de aprender. Generalmente los algoritmos parametricos tienen un alto sesgo haciendolos m√°s r√°pidos de aprender y m√°s faciles de entender, pero generalmente menos flexibles. 

- **Bajo Sesgo:** sugieren m√°s asunciones sobre el formulario de la funcion objetivo.
  Ej: _Decision trees, k-Nearest Neighbors y Support Vector Machines._
- **Alto Sesgo:** sugieren menos asunciones sobre el formulario de la funcion objetivo.
  Ej: _Linear Regression, Linear Discriminant Analysis y Logistic Regression._

### Error de varianza

La varianza es la cantidad que la estimaci√≥n de la funcion objetivo cambiar√° si se usa diferentes datos de entrenamiento. La funci√≥n objetivo es estimada por la informaci√≥n de entrenamiento por un algoritmo de ML, entonces debemos esperar que el algoritmo tenga alguna varianza. 

Si el algoritmo es bueno este sacar√≠a el subyacente mapeo de las variables de entrada a las de salida. 
Los algoritmos de ML con alta varianza son fuertemente influenciados por las especificaciones de los datos de entrenamiento. Esto significa que la espeficiaci√≥n de los entrenamientos influencian el numero y tipo de parametros usados para caracterizar la funcion mapeo.

- **Baja Varianza:** sugiere pequenos cambios de estimaci√≥n de la funci√≥n objetivo con cambios del conjunto de datos de entrenamiento.
  Ej: _Linear Regression, Linear Discriminant Analysis y Logistic Regression._
- **Alta Varianza:** sugiere grandes cambios de estimaci√≥n de la funci√≥n objetivo con cambios del conjunto de datos de entrenamiento.
  Ej: _Decision trees, k-Nearest Neighbors y Support Vector Machines._
 

### Compensaci√≥n de sesgo y varianza

La meta de cualquier algoritmo de ML supervisado es lograr bajo sesgo y baja varianza. En cambio el algoritmo debe alcanzar buena performance de predicci√≥n. 

- Algoritmos param√©tricos o lineales de ML aveces tienen algo sesgo pero baja varianza.
- Algoritmos no param√©tricos o no lineales de ML aveces tienen algo varianza pero bajo sesgo.
  
La parametrizaci√≥n de algoritmos de ML aveces es una batalla sin balance entre sesgo y varianza. Algunos ejemplos:

- El Algoritmo k-Nearest Neighbors tiene bajo sesgo y alta varianza, pero la compensaci√≥n puede cambiar por incremento del valor de $k$ cuando incrementa el numero de neighbors que contribuyen a la predicci√≥n $t$ y en cambio incrementan el sesgo del modelo.
- El Algoritmo Support Vector Machines tiene bajo sesgo y alta varianza, pero la compensaci√≥n puede cambiar por incremento del valor de $C$ influencia el numero de violaciones de margen permitido en el dato de entrenamiento que incrementa el sesgo pero disminuye la varianza.

Existe un equilibrio entre estas preocupaciones y los algoritmos seleccionados, junto con su configuraci√≥n, encuentran diversos equilibrios para abordar este balance en el problema. Aunque no podemos calcular los errores de varianza y sesgo reales debido a la falta de conocimiento sobre la funci√≥n objetivo subyacente, estos t√©rminos proporcionan un marco para comprender c√≥mo los algoritmos de aprendizaje autom√°tico se comportan en su b√∫squeda de rendimiento predictivo.


> ***Cap√≠tulo 7 ‚ÄúOverfitting and Underfitting‚Äù***

La causa del rendimiento deficiente en el aprendizaje autom√°tico es el ajuste excesivo o insuficiente de los datos.

- Ese sobreajuste se refiere a aprender demasiado bien los datos de entrenamiento a expensas de no generalizar bien a datos nuevos.
- Ese subajuste se refiere a falla al aprender suficientemente el problema de los datos de entrenamiento.
- El sobreajuste es el problema m√°s com√∫n de hecho y puede abordarse mediante el uso de m√©todos de re-muestreo y un conjunto de verificaci√≥n retenido.

### Generalizaci√≥n en ML

En ML describimos la funcion objetivo de aprendizaje desde datos de entrenamiento como aprendizaje inductivo. Inducci√≥n refiere a aprender conceptos generales desde ejemplos especificos que es exactamente el problema que el ML supervisado ayuda a resolver. 
Generalizaci√≥n refiere a que tan bien los conceptos aprendidos por un modelo de ML aplican a ejemplos no vistos cuando el modelo estaba siendo entrenado.
La meta de un buen modelo de ML es generalizar bien desde los datos de entrenamiento hacia cualquier dato de un problema dominio.

### Ajuste estad√≠stico

En estadistica se refiere a que tan bien se aproxima a la funci√≥n objetivo.  Este es un buen t√©rmino para usar en el aprendizaje autom√°tico, ya que los algoritmos de aprendizaje autom√°tico supervisados buscan aproximar la funci√≥n de mapeo subyacente desconocida de las variables de salida dadas las variables de entrada.

### Sobreajuste en ML

El sobre ajuste se da cuando cargamos demasiado el modelo de aprendizaje con detalles, que afecta el rendimiento negativamente.
Afecta negativamente en la habilidad del modelo para generalizar desde los datos de entrenamiento a datos nuevos.
El sobreajuste es m√°s parecido con modelos no parametricos y no lineales, que tienen m√°s flexibilidad cuando estan aprendiendo la funci√≥n objetivo.
Muchos algoritmos de ML no parametricos incluyen parametros o tecnicas que limitan y restringen que tan detallado aprende el modelo de aprendizaje.
Ej: decision trees son algoritmos de ML no parametricos que es muy flexible y sujeto a sobreajuste de datos de entrenamiento.
Este problema puede abordarse podando un √°rbol despu√©s de que ha aprendido, con el fin de eliminar algunos de los detalles que ha capturado.

### Subajuste en ML

El subajuste se refiere a un modelo que no puede modelar los datos de entrenamiento ni generalizar a nuevos datos. Este tipo de modelo tiene un rendimiento deficiente en los datos de entrenamiento y no es adecuado. Aunque no se discute mucho, se puede detectar f√°cilmente mediante m√©tricas de rendimiento. La soluci√≥n es probar otros algoritmos de aprendizaje autom√°tico, y contrasta con el problema del sobreajuste.

### Un buen ajuste en ML

El buen ajuste se refiere a un modelo que captura la esencia subyacente de los datos de entrenamiento, pero puede generalizar bien a nuevos datos. Un buen ajuste es el objetivo de cualquier modelo de aprendizaje autom√°tico supervisado. Aunque no se discute mucho, se puede detectar f√°cilmente mediante m√©tricas de rendimiento. La soluci√≥n es probar otros algoritmos de aprendizaje autom√°tico, y contrasta con los problemas de sobreajuste y subajuste.

### Como limitar el sobreajuste

Tanto sobreajuste como subajuste pueden llevar a un pobre modelo de rendimiento. Pero el sobreajuste es el problema m√°s com√∫n. Hay dos tipos de t√©cnicas que se pueden aplicar para limitar el sobreajuste:
1. Usar una t√©cnica de remuestreo para estimar la certeza del modelo.
2. Mantener un conjunto de datos de validaci√≥n.

La t√©cnica ma√°s popular para remuestreo es k-fold cross-validation. Este te permite entrenar y probar tu modelo k-veces en diferentes subconjuntos de datos de entrenamiento y construir una estimaci√≥n del rendimiento del modelo de ML en datos no vistos.
Una validac√≥n del conjunto de datos es simplemente un subconjunto de tus datos de entrenamiento que mantienes desde tus algoritmos de ML hasta el final mismo del proyecto. Despues que hayas seleccionado y modificado tus algoritmos de Ml con conjuntos de datos de entrenamiento para evaluar los modelos aprendidos.
Utilizar la validaci√≥n cruzada es un est√°ndar de oro en el aprendizaje autom√°tico aplicado para estimar la precisi√≥n del modelo en datos no vistos. Si tienes los datos, utilizar un conjunto de validaci√≥n tambi√©n es una pr√°ctica excelente.